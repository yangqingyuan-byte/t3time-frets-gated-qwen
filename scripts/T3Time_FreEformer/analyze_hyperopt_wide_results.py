#!/usr/bin/env python3
"""
åˆ†æ T3Time_FreEformer_Gated_Qwen å¤§èŒƒå›´å‚æ•°å¯»ä¼˜ç»“æœè„šæœ¬
ä»¿ç…§ FreTS çš„åˆ†æé£æ ¼ï¼Œä» experiment_results.log ä¸­æ‰¾å‡ºæœ€ä¼˜ç»„åˆ
"""

import json
import argparse
from collections import defaultdict


def load_results(result_file, model_id_prefix):
    results = []
    try:
        with open(result_file, "r") as f:
            for line in f:
                line = line.strip()
                if not line:
                    continue
                try:
                    data = json.loads(line)
                except json.JSONDecodeError:
                    continue
                if data.get("model_id", "").startswith(model_id_prefix):
                    results.append(data)
    except FileNotFoundError:
        print(f"âŒ ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {result_file}")
    return results


def main():
    parser = argparse.ArgumentParser(
        description="åˆ†æ T3Time_FreEformer_Gated_Qwen å¤§èŒƒå›´å‚æ•°å¯»ä¼˜ç»“æœ"
    )
    parser.add_argument(
        "--result_file",
        type=str,
        default="/root/0/T3Time/experiment_results.log",
        help="ç»“æœæ–‡ä»¶è·¯å¾„",
    )
    parser.add_argument(
        "--model_id_prefix",
        type=str,
        default="T3Time_FreEformer_Wide_ETTh1_pred96",
        help="æ¨¡å‹IDå‰ç¼€ï¼ˆä¸å¯»ä¼˜è„šæœ¬ä¸­çš„ MODEL_ID_PREFIX å¯¹é½ï¼‰",
    )
    parser.add_argument(
        "--topk", type=int, default=10, help="æ˜¾ç¤ºå‰å¤šå°‘ä¸ªæœ€ä¼˜ç»“æœ"
    )
    args = parser.parse_args()

    print("=" * 80)
    print("T3Time_FreEformer_Gated_Qwen å¤§èŒƒå›´å‚æ•°å¯»ä¼˜ç»“æœåˆ†æ")
    print("=" * 80)

    results = load_results(args.result_file, args.model_id_prefix)
    if not results:
        print(
            f"âŒ æœªæ‰¾åˆ°ä»¥ '{args.model_id_prefix}' å¼€å¤´çš„å®éªŒç»“æœï¼Œè¯·ç¡®è®¤å¯»ä¼˜è„šæœ¬å·²è¿è¡Œå®Œæˆã€‚"
        )
        return

    print(f"å…±æ‰¾åˆ° {len(results)} æ¡å®éªŒç»“æœ")

    # æŒ‰ MSE æ’åº
    sorted_by_mse = sorted(results, key=lambda x: x.get("test_mse", 1e9))
    # æŒ‰ MAE æ’åº
    sorted_by_mae = sorted(results, key=lambda x: x.get("test_mae", 1e9))

    print("\n" + "=" * 80)
    print(f"ğŸ† Top {min(args.topk, len(sorted_by_mse))} æœ€ä¼˜ç»“æœï¼ˆæŒ‰ Test MSE æ’åºï¼‰")
    print("=" * 80)
    print(
        f"{'Rank':<5} {'MSE':<10} {'MAE':<10} {'Channel':<8} "
        f"{'FreL':<5} {'Emb':<5} {'LR':<10} {'Drop':<6} "
        f"{'WD':<10} {'BS':<5} {'Seed':<6} {'Time':<19}"
    )
    print("-" * 80)

    for idx, r in enumerate(sorted_by_mse[: args.topk], start=1):
        print(
            f"{idx:<5}"
            f"{r.get('test_mse', 0):<10.6f}"
            f"{r.get('test_mae', 0):<10.6f}"
            f"{str(r.get('channel', '')):<8}"
            f"{str(r.get('fre_e_layer', '')):<5}"
            f"{str(r.get('embed_size', '')):<5}"
            f"{r.get('learning_rate', 0):<10.6f}"
            f"{r.get('dropout_n', 0):<6.2f}"
            f"{r.get('weight_decay', 0):<10.2e}"
            f"{str(r.get('batch_size', '')):<5}"
            f"{str(r.get('seed', '')):<6}"
            f"{str(r.get('timestamp', '')):<19}"
        )

    print("\n" + "=" * 80)
    print(f"ğŸ† Top {min(args.topk, len(sorted_by_mae))} æœ€ä¼˜ç»“æœï¼ˆæŒ‰ Test MAE æ’åºï¼‰")
    print("=" * 80)
    print(
        f"{'Rank':<5} {'MSE':<10} {'MAE':<10} {'Channel':<8} "
        f"{'FreL':<5} {'Emb':<5} {'LR':<10} {'Drop':<6} "
        f"{'WD':<10} {'BS':<5} {'Seed':<6} {'Time':<19}"
    )
    print("-" * 80)

    for idx, r in enumerate(sorted_by_mae[: args.topk], start=1):
        print(
            f"{idx:<5}"
            f"{r.get('test_mse', 0):<10.6f}"
            f"{r.get('test_mae', 0):<10.6f}"
            f"{str(r.get('channel', '')):<8}"
            f"{str(r.get('fre_e_layer', '')):<5}"
            f"{str(r.get('embed_size', '')):<5}"
            f"{r.get('learning_rate', 0):<10.6f}"
            f"{r.get('dropout_n', 0):<6.2f}"
            f"{r.get('weight_decay', 0):<10.2e}"
            f"{str(r.get('batch_size', '')):<5}"
            f"{str(r.get('seed', '')):<6}"
            f"{str(r.get('timestamp', '')):<19}"
        )

    # æ‰¾å‡ºæœ€ä½³ MSE
    best_mse = sorted_by_mse[0]
    # æ‰¾å‡ºæœ€ä½³ MAE
    best_mae = sorted_by_mae[0]

    print("\n" + "=" * 80)
    print("ğŸ¯ æœ€ä½³ MSE å‚æ•°ç»„åˆ")
    print("=" * 80)
    print(f"  Test MSE: {best_mse.get('test_mse', 0):.6f}")
    print(f"  Test MAE: {best_mse.get('test_mae', 0):.6f}")
    print(f"  Channel: {best_mse.get('channel')}")
    print(f"  Fre_E_Layer: {best_mse.get('fre_e_layer')}")
    print(f"  Embed_Size: {best_mse.get('embed_size')}")
    print(f"  Learning_Rate: {best_mse.get('learning_rate')}")
    print(f"  Dropout: {best_mse.get('dropout_n')}")
    print(f"  Weight_Decay: {best_mse.get('weight_decay')}")
    print(f"  Batch_Size: {best_mse.get('batch_size')}")
    print(f"  Seed: {best_mse.get('seed')}")
    print(f"  Timestamp: {best_mse.get('timestamp')}")

    print("\n" + "=" * 80)
    print("ğŸ¯ æœ€ä½³ MAE å‚æ•°ç»„åˆ")
    print("=" * 80)
    print(f"  Test MSE: {best_mae.get('test_mse', 0):.6f}")
    print(f"  Test MAE: {best_mae.get('test_mae', 0):.6f}")
    print(f"  Channel: {best_mae.get('channel')}")
    print(f"  Fre_E_Layer: {best_mae.get('fre_e_layer')}")
    print(f"  Embed_Size: {best_mae.get('embed_size')}")
    print(f"  Learning_Rate: {best_mae.get('learning_rate')}")
    print(f"  Dropout: {best_mae.get('dropout_n')}")
    print(f"  Weight_Decay: {best_mae.get('weight_decay')}")
    print(f"  Batch_Size: {best_mae.get('batch_size')}")
    print(f"  Seed: {best_mae.get('seed')}")
    print(f"  Timestamp: {best_mae.get('timestamp')}")

    # å¦‚æœæœ€ä½³MSEå’Œæœ€ä½³MAEæ˜¯åŒä¸€ä¸ªç»“æœï¼Œç»™å‡ºæç¤º
    if best_mse.get('model_id') == best_mae.get('model_id'):
        print("\n" + "=" * 80)
        print("âœ… æœ€ä½³ MSE å’Œæœ€ä½³ MAE æ˜¯åŒä¸€ä¸ªå®éªŒï¼")
        print("=" * 80)
    else:
        print("\n" + "=" * 80)
        print("â„¹ï¸  æœ€ä½³ MSE å’Œæœ€ä½³ MAE æ¥è‡ªä¸åŒçš„å®éªŒ")
        print("=" * 80)
        print(f"  æœ€ä½³ MSE çš„ MAE: {best_mse.get('test_mae', 0):.6f}")
        print(f"  æœ€ä½³ MAE çš„ MSE: {best_mae.get('test_mse', 0):.6f}")

    # æŒ‰ Channel èšåˆçš„æœ€ä¼˜ç»“æœï¼ˆæŒ‰ MSEï¼‰
    print("\n" + "=" * 80)
    print("æŒ‰ Channel èšåˆçš„æœ€ä¼˜ç»“æœï¼ˆæŒ‰ MSEï¼‰")
    print("=" * 80)
    best_by_channel_mse = {}
    for r in results:
        ch = r.get("channel")
        mse = r.get("test_mse", 1e9)
        if ch not in best_by_channel_mse or mse < best_by_channel_mse[ch]["test_mse"]:
            best_by_channel_mse[ch] = r
    for ch in sorted(best_by_channel_mse.keys()):
        r = best_by_channel_mse[ch]
        print(
            f"  Channel {ch}: "
            f"MSE={r.get('test_mse', 0):.6f}, "
            f"MAE={r.get('test_mae', 0):.6f}, "
            f"Fre_E_Layer={r.get('fre_e_layer')}, "
            f"Embed_Size={r.get('embed_size')}, "
            f"LR={r.get('learning_rate')}, "
            f"Dropout={r.get('dropout_n')}, "
            f"BS={r.get('batch_size')}"
        )

    # æŒ‰ Channel èšåˆçš„æœ€ä¼˜ç»“æœï¼ˆæŒ‰ MAEï¼‰
    print("\n" + "=" * 80)
    print("æŒ‰ Channel èšåˆçš„æœ€ä¼˜ç»“æœï¼ˆæŒ‰ MAEï¼‰")
    print("=" * 80)
    best_by_channel_mae = {}
    for r in results:
        ch = r.get("channel")
        mae = r.get("test_mae", 1e9)
        if ch not in best_by_channel_mae or mae < best_by_channel_mae[ch]["test_mae"]:
            best_by_channel_mae[ch] = r
    for ch in sorted(best_by_channel_mae.keys()):
        r = best_by_channel_mae[ch]
        print(
            f"  Channel {ch}: "
            f"MSE={r.get('test_mse', 0):.6f}, "
            f"MAE={r.get('test_mae', 0):.6f}, "
            f"Fre_E_Layer={r.get('fre_e_layer')}, "
            f"Embed_Size={r.get('embed_size')}, "
            f"LR={r.get('learning_rate')}, "
            f"Dropout={r.get('dropout_n')}, "
            f"BS={r.get('batch_size')}"
        )

    print("\n" + "=" * 80)
    print("âœ… åˆ†æå®Œæˆ")
    print("=" * 80)


if __name__ == "__main__":
    main()


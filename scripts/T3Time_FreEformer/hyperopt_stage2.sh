#!/bin/bash
# T3Time_FreEformer_Gated_Qwen é˜¶æ®µ2å‚æ•°å¯»ä¼˜è„šæœ¬
# é˜¶æ®µ2ï¼šè®­ç»ƒå‚æ•°å¯»ä¼˜ï¼ˆlearning_rate â†’ dropout_n â†’ batch_sizeï¼‰

set -uo pipefail

# æ¿€æ´» conda çŽ¯å¢ƒ
eval "$(conda shell.bash hook)" 2>/dev/null || true
conda activate TimeCMA_Qwen3 2>/dev/null || source activate TimeCMA_Qwen3 2>/dev/null || true

# è®¾ç½®çŽ¯å¢ƒå˜é‡
export PYTHONPATH="/root/0/T3Time:${PYTHONPATH-}"
export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True
export CUDA_VISIBLE_DEVICES=0

LOG_DIR="/root/0/T3Time/Results/T3Time_FreEformer/Stage2"
RESULT_LOG="/root/0/T3Time/experiment_results.log"
mkdir -p "${LOG_DIR}"

# å›ºå®šå‚æ•°ï¼ˆåŸºäºŽé˜¶æ®µ1çš„æœ€ä½³ç»“æžœï¼‰
DATA_PATH="ETTh1"
SEQ_LEN=96
PRED_LEN=96
NUM_NODES=7
CHANNEL=32
FRE_E_LAYER=1
EMBED_SIZE=8
E_LAYER=1
D_LAYER=1
HEAD=8
EPOCHS=50
ES_PATIENCE=10
LRADJ="type1"
EMBED_VERSION="qwen3_0.6b"
SEED=2021
WEIGHT_DECAY=1e-4
LOSS_FN="smooth_l1"
MODEL_ID_PREFIX="T3Time_FreEformer_Stage2"

echo "=========================================="
echo "T3Time_FreEformer_Gated_Qwen é˜¶æ®µ2å‚æ•°å¯»ä¼˜"
echo "=========================================="
echo "å›ºå®šå‚æ•°ï¼ˆé˜¶æ®µ1æœ€ä½³ç»“æžœï¼‰:"
echo "  Channel: ${CHANNEL}"
echo "  Fre_E_Layer: ${FRE_E_LAYER}"
echo "  Embed_Size: ${EMBED_SIZE}"
echo "  E_Layer: ${E_LAYER}, D_Layer: ${D_LAYER}"
echo "  Head: ${HEAD}"
echo "  Seed: ${SEED}"
echo "=========================================="

# æ­¥éª¤2.1: learning_rate å¯»ä¼˜
echo ""
echo "=========================================="
echo "æ­¥éª¤ 2.1: Learning_Rate å¯»ä¼˜"
echo "=========================================="
LEARNING_RATES=(5e-5 7.5e-5 1e-4 1.5e-4)
DROPOUT_N=0.1
BATCH_SIZE=32

best_learning_rate=""
best_learning_rate_mse=999999.0

for learning_rate in "${LEARNING_RATES[@]}"; do
    MODEL_ID="${MODEL_ID_PREFIX}_Step2_1_LR${learning_rate}"
    LOG_FILE="${LOG_DIR}/${MODEL_ID}_${SEED}.log"
    
    echo ""
    echo "----------------------------------------"
    echo "å®žéªŒ: Learning_Rate=${learning_rate}, Dropout=${DROPOUT_N}, Batch_Size=${BATCH_SIZE}"
    echo "Model_ID: ${MODEL_ID}"
    echo "----------------------------------------"
    
    python -u train_freeformer_gated_qwen.py \
        --data_path "${DATA_PATH}" \
        --seq_len "${SEQ_LEN}" \
        --pred_len "${PRED_LEN}" \
        --num_nodes "${NUM_NODES}" \
        --batch_size "${BATCH_SIZE}" \
        --learning_rate "${learning_rate}" \
        --dropout_n "${DROPOUT_N}" \
        --channel "${CHANNEL}" \
        --e_layer "${E_LAYER}" \
        --d_layer "${D_LAYER}" \
        --head "${HEAD}" \
        --epochs "${EPOCHS}" \
        --es_patience "${ES_PATIENCE}" \
        --lradj "${LRADJ}" \
        --embed_version "${EMBED_VERSION}" \
        --seed "${SEED}" \
        --weight_decay "${WEIGHT_DECAY}" \
        --loss_fn "${LOSS_FN}" \
        --model_id "${MODEL_ID}" \
        --embed_size "${EMBED_SIZE}" \
        --fre_e_layer "${FRE_E_LAYER}" \
        > "${LOG_FILE}" 2>&1
    
    if [ $? -eq 0 ]; then
        mse=$(grep "Test MSE:" "${LOG_FILE}" | tail -1 | awk '{print $NF}')
        if [ -n "${mse}" ] && [ "${mse}" != "0" ]; then
            echo "âœ… Learning_Rate=${learning_rate}: MSE=${mse}"
            comparison=$(python3 -c "print(1 if ${mse} < ${best_learning_rate_mse} else 0)")
            if [ "${comparison}" = "1" ]; then
                best_learning_rate_mse=${mse}
                best_learning_rate=${learning_rate}
                echo "  ðŸ† æ–°çš„æœ€ä½³ Learning_Rate: ${best_learning_rate} (MSE: ${best_learning_rate_mse})"
            fi
        else
            echo "âš ï¸  æœªèƒ½ä»Žæ—¥å¿—ä¸­æå– MSE"
        fi
    else
        echo "âŒ å®žéªŒå¤±è´¥ï¼ŒæŸ¥çœ‹æ—¥å¿—: ${LOG_FILE}"
    fi
done

if [ -z "${best_learning_rate}" ]; then
    echo "âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Learning_Rate ç»“æžœï¼Œé€€å‡º"
    exit 1
fi

echo ""
echo "=========================================="
echo "æ­¥éª¤ 2.1 å®Œæˆ: æœ€ä½³ Learning_Rate = ${best_learning_rate} (MSE: ${best_learning_rate_mse})"
echo "=========================================="

# æ­¥éª¤2.2: dropout_n å¯»ä¼˜ï¼ˆå›ºå®šæœ€ä½³ learning_rateï¼‰
echo ""
echo "=========================================="
echo "æ­¥éª¤ 2.2: Dropout å¯»ä¼˜ï¼ˆLearning_Rate=${best_learning_rate}ï¼‰"
echo "=========================================="
DROPOUTS=(0.1 0.2 0.3 0.4 0.5)
BATCH_SIZE=32

best_dropout=""
best_dropout_mse=999999.0

for dropout_n in "${DROPOUTS[@]}"; do
    MODEL_ID="${MODEL_ID_PREFIX}_Step2_2_LR${best_learning_rate}_Dropout${dropout_n}"
    LOG_FILE="${LOG_DIR}/${MODEL_ID}_${SEED}.log"
    
    echo ""
    echo "----------------------------------------"
    echo "å®žéªŒ: Learning_Rate=${best_learning_rate}, Dropout=${dropout_n}, Batch_Size=${BATCH_SIZE}"
    echo "Model_ID: ${MODEL_ID}"
    echo "----------------------------------------"
    
    python -u train_freeformer_gated_qwen.py \
        --data_path "${DATA_PATH}" \
        --seq_len "${SEQ_LEN}" \
        --pred_len "${PRED_LEN}" \
        --num_nodes "${NUM_NODES}" \
        --batch_size "${BATCH_SIZE}" \
        --learning_rate "${best_learning_rate}" \
        --dropout_n "${dropout_n}" \
        --channel "${CHANNEL}" \
        --e_layer "${E_LAYER}" \
        --d_layer "${D_LAYER}" \
        --head "${HEAD}" \
        --epochs "${EPOCHS}" \
        --es_patience "${ES_PATIENCE}" \
        --lradj "${LRADJ}" \
        --embed_version "${EMBED_VERSION}" \
        --seed "${SEED}" \
        --weight_decay "${WEIGHT_DECAY}" \
        --loss_fn "${LOSS_FN}" \
        --model_id "${MODEL_ID}" \
        --embed_size "${EMBED_SIZE}" \
        --fre_e_layer "${FRE_E_LAYER}" \
        > "${LOG_FILE}" 2>&1
    
    if [ $? -eq 0 ]; then
        mse=$(grep "Test MSE:" "${LOG_FILE}" | tail -1 | awk '{print $NF}')
        if [ -n "${mse}" ] && [ "${mse}" != "0" ]; then
            echo "âœ… Dropout=${dropout_n}: MSE=${mse}"
            comparison=$(python3 -c "print(1 if ${mse} < ${best_dropout_mse} else 0)")
            if [ "${comparison}" = "1" ]; then
                best_dropout_mse=${mse}
                best_dropout=${dropout_n}
                echo "  ðŸ† æ–°çš„æœ€ä½³ Dropout: ${best_dropout} (MSE: ${best_dropout_mse})"
            fi
        else
            echo "âš ï¸  æœªèƒ½ä»Žæ—¥å¿—ä¸­æå– MSE"
        fi
    else
        echo "âŒ å®žéªŒå¤±è´¥ï¼ŒæŸ¥çœ‹æ—¥å¿—: ${LOG_FILE}"
    fi
done

if [ -z "${best_dropout}" ]; then
    echo "âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Dropout ç»“æžœï¼Œé€€å‡º"
    exit 1
fi

echo ""
echo "=========================================="
echo "æ­¥éª¤ 2.2 å®Œæˆ: æœ€ä½³ Dropout = ${best_dropout} (MSE: ${best_dropout_mse})"
echo "=========================================="

# æ­¥éª¤2.3: batch_size å¯»ä¼˜ï¼ˆå›ºå®šå‰ä¸¤è€…ï¼‰
echo ""
echo "=========================================="
echo "æ­¥éª¤ 2.3: Batch_Size å¯»ä¼˜ï¼ˆLearning_Rate=${best_learning_rate}, Dropout=${best_dropout}ï¼‰"
echo "=========================================="
BATCH_SIZES=(16 32 64)

best_batch_size=""
best_batch_size_mse=999999.0

for batch_size in "${BATCH_SIZES[@]}"; do
    MODEL_ID="${MODEL_ID_PREFIX}_Step2_3_LR${best_learning_rate}_Dropout${best_dropout}_Batch${batch_size}"
    LOG_FILE="${LOG_DIR}/${MODEL_ID}_${SEED}.log"
    
    echo ""
    echo "----------------------------------------"
    echo "å®žéªŒ: Learning_Rate=${best_learning_rate}, Dropout=${best_dropout}, Batch_Size=${batch_size}"
    echo "Model_ID: ${MODEL_ID}"
    echo "----------------------------------------"
    
    python -u train_freeformer_gated_qwen.py \
        --data_path "${DATA_PATH}" \
        --seq_len "${SEQ_LEN}" \
        --pred_len "${PRED_LEN}" \
        --num_nodes "${NUM_NODES}" \
        --batch_size "${batch_size}" \
        --learning_rate "${best_learning_rate}" \
        --dropout_n "${best_dropout}" \
        --channel "${CHANNEL}" \
        --e_layer "${E_LAYER}" \
        --d_layer "${D_LAYER}" \
        --head "${HEAD}" \
        --epochs "${EPOCHS}" \
        --es_patience "${ES_PATIENCE}" \
        --lradj "${LRADJ}" \
        --embed_version "${EMBED_VERSION}" \
        --seed "${SEED}" \
        --weight_decay "${WEIGHT_DECAY}" \
        --loss_fn "${LOSS_FN}" \
        --model_id "${MODEL_ID}" \
        --embed_size "${EMBED_SIZE}" \
        --fre_e_layer "${FRE_E_LAYER}" \
        > "${LOG_FILE}" 2>&1
    
    if [ $? -eq 0 ]; then
        mse=$(grep "Test MSE:" "${LOG_FILE}" | tail -1 | awk '{print $NF}')
        if [ -n "${mse}" ] && [ "${mse}" != "0" ]; then
            echo "âœ… Batch_Size=${batch_size}: MSE=${mse}"
            comparison=$(python3 -c "print(1 if ${mse} < ${best_batch_size_mse} else 0)")
            if [ "${comparison}" = "1" ]; then
                best_batch_size_mse=${mse}
                best_batch_size=${batch_size}
                echo "  ðŸ† æ–°çš„æœ€ä½³ Batch_Size: ${best_batch_size} (MSE: ${best_batch_size_mse})"
            fi
        else
            echo "âš ï¸  æœªèƒ½ä»Žæ—¥å¿—ä¸­æå– MSE"
        fi
    else
        echo "âŒ å®žéªŒå¤±è´¥ï¼ŒæŸ¥çœ‹æ—¥å¿—: ${LOG_FILE}"
    fi
done

if [ -z "${best_batch_size}" ]; then
    echo "âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„ Batch_Size ç»“æžœï¼Œé€€å‡º"
    exit 1
fi

echo ""
echo "=========================================="
echo "é˜¶æ®µ2å®Œæˆï¼"
echo "=========================================="
echo "æœ€ä½³å‚æ•°ç»„åˆ:"
echo "  Channel: ${CHANNEL}"
echo "  Fre_E_Layer: ${FRE_E_LAYER}"
echo "  Embed_Size: ${EMBED_SIZE}"
echo "  Learning_Rate: ${best_learning_rate}"
echo "  Dropout: ${best_dropout}"
echo "  Batch_Size: ${best_batch_size}"
echo "  æœ€ç»ˆ MSE: ${best_batch_size_mse}"
echo "=========================================="
echo ""
echo "æ‰€æœ‰ç»“æžœå·²ä¿å­˜åˆ°: ${RESULT_LOG}"
echo "æ—¥å¿—æ–‡ä»¶ä¿å­˜åœ¨: ${LOG_DIR}"
echo ""
echo "è¿è¡Œåˆ†æžè„šæœ¬æŸ¥çœ‹è¯¦ç»†ç»“æžœ:"
echo "  python scripts/T3Time_FreEformer/analyze_stage2_results.py"

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
åˆ†æç¼–ç å™¨å’Œè§£ç å™¨å±‚æ•°å¯»ä¼˜å®éªŒç»“æœ
é‡ç‚¹åˆ†æå±‚æ•°å¯¹MSEæŒ‡æ ‡çš„å½±å“
"""
import json
import os
import sys
from collections import defaultdict
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

def load_layer_search_results(result_file=None, seed=2088, model_id_prefix="T3Time_FreTS_Gated_Qwen_LayerSearch"):
    """åŠ è½½å±‚æ•°å¯»ä¼˜å®éªŒç»“æœ"""
    if result_file is None:
        result_file = os.path.join(project_root, "experiment_results.log")
    
    results = []
    
    if not os.path.exists(result_file):
        print(f"âŒ ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {result_file}")
        return results
    
    with open(result_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            if not line.strip():
                continue
            try:
                data = json.loads(line.strip())
                # æ£€æŸ¥æ˜¯å¦æ˜¯å±‚æ•°å¯»ä¼˜å®éªŒç»“æœ
                if (data.get('seed') == seed and 
                    data.get('model_id', '').startswith(model_id_prefix)):
                    results.append(data)
            except json.JSONDecodeError as e:
                continue
            except Exception as e:
                continue
    
    return results

def analyze_layer_impact(results):
    """åˆ†æå±‚æ•°å¯¹MSEçš„å½±å“"""
    if not results:
        return None, None, None, None
    
    # æŒ‰MSEæ’åº
    sorted_results = sorted(results, key=lambda x: x.get('test_mse', float('inf')))
    
    # æŒ‰E_Layeråˆ†ç»„ç»Ÿè®¡
    e_layer_stats = defaultdict(list)
    for r in results:
        e_layer = r.get('e_layer')
        mse = r.get('test_mse', float('inf'))
        mae = r.get('test_mae', float('inf'))
        if e_layer is not None:
            e_layer_stats[e_layer].append({'mse': mse, 'mae': mae})
    
    # æŒ‰D_Layeråˆ†ç»„ç»Ÿè®¡
    d_layer_stats = defaultdict(list)
    for r in results:
        d_layer = r.get('d_layer')
        mse = r.get('test_mse', float('inf'))
        mae = r.get('test_mae', float('inf'))
        if d_layer is not None:
            d_layer_stats[d_layer].append({'mse': mse, 'mae': mae})
    
    # æŒ‰(E_Layer, D_Layer)ç»„åˆç»Ÿè®¡
    layer_combo_stats = defaultdict(list)
    for r in results:
        e_layer = r.get('e_layer')
        d_layer = r.get('d_layer')
        mse = r.get('test_mse', float('inf'))
        mae = r.get('test_mae', float('inf'))
        if e_layer is not None and d_layer is not None:
            layer_combo_stats[(e_layer, d_layer)].append({'mse': mse, 'mae': mae})
    
    return sorted_results, e_layer_stats, d_layer_stats, layer_combo_stats

def print_analysis(sorted_results, e_layer_stats, d_layer_stats, layer_combo_stats):
    """æ‰“å°åˆ†æç»“æœ"""
    print("="*80)
    print("ç¼–ç å™¨å’Œè§£ç å™¨å±‚æ•°å¯»ä¼˜ç»“æœåˆ†æ")
    print("="*80)
    
    if not sorted_results:
        print("\nâŒ æœªæ‰¾åˆ°å®éªŒç»“æœ")
        return
    
    total_results = len(sorted_results)
    print(f"\næ‰¾åˆ° {total_results} æ¡å®éªŒç»“æœ\n")
    
    # æœ€ä½³ç»“æœ
    best = sorted_results[0]
    print("="*80)
    print("ğŸ† æœ€ä½³ç»“æœï¼ˆæœ€å°MSEï¼‰")
    print("="*80)
    print(f"E_Layer:     {best.get('e_layer', 'N/A')}")
    print(f"D_Layer:     {best.get('d_layer', 'N/A')}")
    print(f"MSE:         {best.get('test_mse', 'N/A'):.6f}")
    print(f"MAE:         {best.get('test_mae', 'N/A'):.6f}")
    print(f"Timestamp:   {best.get('timestamp', 'N/A')}")
    
    # æ‰€æœ‰ç»“æœè¡¨æ ¼
    print("\n" + "="*80)
    print("æ‰€æœ‰å®éªŒç»“æœï¼ˆæŒ‰MSEæ’åºï¼‰")
    print("="*80)
    print(f"{'Rank':<6} {'E_Layer':<10} {'D_Layer':<10} {'MSE':<15} {'MAE':<15}")
    print("-"*80)
    
    for i, r in enumerate(sorted_results, 1):
        print(f"{i:<6} {r.get('e_layer', 'N/A'):<10} {r.get('d_layer', 'N/A'):<10} "
              f"{r.get('test_mse', 'N/A'):<15.6f} {r.get('test_mae', 'N/A'):<15.6f}")
    
    # E_Layer å½±å“åˆ†æ
    print("\n" + "="*80)
    print("ğŸ“Š ç¼–ç å™¨å±‚æ•° (E_Layer) å¯¹MSEçš„å½±å“")
    print("="*80)
    print(f"{'E_Layer':<10} {'å¹³å‡MSE':<15} {'æœ€å°MSE':<15} {'æœ€å¤§MSE':<15} {'å¹³å‡MAE':<15} {'å®éªŒæ•°':<8}")
    print("-"*80)
    
    for e_layer in sorted(e_layer_stats.keys()):
        stats = e_layer_stats[e_layer]
        mse_list = [s['mse'] for s in stats]
        mae_list = [s['mae'] for s in stats]
        print(f"{e_layer:<10} "
              f"{np.mean(mse_list):<15.6f} "
              f"{np.min(mse_list):<15.6f} "
              f"{np.max(mse_list):<15.6f} "
              f"{np.mean(mae_list):<15.6f} "
              f"{len(stats):<8}")
    
    # D_Layer å½±å“åˆ†æ
    print("\n" + "="*80)
    print("ğŸ“Š è§£ç å™¨å±‚æ•° (D_Layer) å¯¹MSEçš„å½±å“")
    print("="*80)
    print(f"{'D_Layer':<10} {'å¹³å‡MSE':<15} {'æœ€å°MSE':<15} {'æœ€å¤§MSE':<15} {'å¹³å‡MAE':<15} {'å®éªŒæ•°':<8}")
    print("-"*80)
    
    for d_layer in sorted(d_layer_stats.keys()):
        stats = d_layer_stats[d_layer]
        mse_list = [s['mse'] for s in stats]
        mae_list = [s['mae'] for s in stats]
        print(f"{d_layer:<10} "
              f"{np.mean(mse_list):<15.6f} "
              f"{np.min(mse_list):<15.6f} "
              f"{np.max(mse_list):<15.6f} "
              f"{np.mean(mae_list):<15.6f} "
              f"{len(stats):<8}")
    
    # å±‚æ•°ç»„åˆå½±å“åˆ†æ
    print("\n" + "="*80)
    print("ğŸ“Š å±‚æ•°ç»„åˆ (E_Layer, D_Layer) å¯¹MSEçš„å½±å“")
    print("="*80)
    print(f"{'E_Layer':<10} {'D_Layer':<10} {'å¹³å‡MSE':<15} {'æœ€å°MSE':<15} {'æœ€å¤§MSE':<15} {'å¹³å‡MAE':<15}")
    print("-"*80)
    
    sorted_combos = sorted(layer_combo_stats.items(), key=lambda x: np.mean([s['mse'] for s in x[1]]))
    for (e_layer, d_layer), stats in sorted_combos:
        mse_list = [s['mse'] for s in stats]
        mae_list = [s['mae'] for s in stats]
        print(f"{e_layer:<10} {d_layer:<10} "
              f"{np.mean(mse_list):<15.6f} "
              f"{np.min(mse_list):<15.6f} "
              f"{np.max(mse_list):<15.6f} "
              f"{np.mean(mae_list):<15.6f}")
    
    # ç»“è®ºåˆ†æ
    print("\n" + "="*80)
    print("ğŸ“ˆ ç»“è®ºåˆ†æ")
    print("="*80)
    
    # æ‰¾å‡ºæœ€ä½³E_Layer
    best_e_layer = min(e_layer_stats.items(), key=lambda x: np.mean([s['mse'] for s in x[1]]))
    print(f"\næœ€ä½³ç¼–ç å™¨å±‚æ•° (E_Layer): {best_e_layer[0]}")
    print(f"  å¹³å‡MSE: {np.mean([s['mse'] for s in best_e_layer[1]]):.6f}")
    
    # æ‰¾å‡ºæœ€ä½³D_Layer
    best_d_layer = min(d_layer_stats.items(), key=lambda x: np.mean([s['mse'] for s in x[1]]))
    print(f"\næœ€ä½³è§£ç å™¨å±‚æ•° (D_Layer): {best_d_layer[0]}")
    print(f"  å¹³å‡MSE: {np.mean([s['mse'] for s in best_d_layer[1]]):.6f}")
    
    # æ‰¾å‡ºæœ€ä½³ç»„åˆ
    best_combo = min(layer_combo_stats.items(), key=lambda x: np.mean([s['mse'] for s in x[1]]))
    (best_e, best_d), best_combo_stats = best_combo
    print(f"\næœ€ä½³å±‚æ•°ç»„åˆ (E_Layer={best_e}, D_Layer={best_d}):")
    print(f"  å¹³å‡MSE: {np.mean([s['mse'] for s in best_combo_stats]):.6f}")
    print(f"  æœ€å°MSE: {np.min([s['mse'] for s in best_combo_stats]):.6f}")
    
    # å±‚æ•°å½±å“è¯„ä¼°
    print("\n" + "="*80)
    print("ğŸ” å±‚æ•°å½±å“è¯„ä¼°")
    print("="*80)
    
    # è®¡ç®—E_Layerçš„MSEå˜åŒ–
    e_layer_mses = {k: np.mean([s['mse'] for s in v]) for k, v in e_layer_stats.items()}
    if len(e_layer_mses) > 1:
        min_e_mse = min(e_layer_mses.values())
        max_e_mse = max(e_layer_mses.values())
        e_impact = ((max_e_mse - min_e_mse) / min_e_mse) * 100
        print(f"\nç¼–ç å™¨å±‚æ•° (E_Layer) å¯¹MSEçš„å½±å“:")
        print(f"  æœ€å°å¹³å‡MSE: {min_e_mse:.6f}")
        print(f"  æœ€å¤§å¹³å‡MSE: {max_e_mse:.6f}")
        print(f"  å½±å“å¹…åº¦: {e_impact:.2f}%")
        if e_impact > 5:
            print(f"  âœ… ç¼–ç å™¨å±‚æ•°å¯¹MSEæœ‰æ˜¾è‘—å½±å“")
        else:
            print(f"  âš ï¸  ç¼–ç å™¨å±‚æ•°å¯¹MSEå½±å“è¾ƒå°")
    
    # è®¡ç®—D_Layerçš„MSEå˜åŒ–
    d_layer_mses = {k: np.mean([s['mse'] for s in v]) for k, v in d_layer_stats.items()}
    if len(d_layer_mses) > 1:
        min_d_mse = min(d_layer_mses.values())
        max_d_mse = max(d_layer_mses.values())
        d_impact = ((max_d_mse - min_d_mse) / min_d_mse) * 100
        print(f"\nè§£ç å™¨å±‚æ•° (D_Layer) å¯¹MSEçš„å½±å“:")
        print(f"  æœ€å°å¹³å‡MSE: {min_d_mse:.6f}")
        print(f"  æœ€å¤§å¹³å‡MSE: {max_d_mse:.6f}")
        print(f"  å½±å“å¹…åº¦: {d_impact:.2f}%")
        if d_impact > 5:
            print(f"  âœ… è§£ç å™¨å±‚æ•°å¯¹MSEæœ‰æ˜¾è‘—å½±å“")
        else:
            print(f"  âš ï¸  è§£ç å™¨å±‚æ•°å¯¹MSEå½±å“è¾ƒå°")
    
    # ä¸åŸºå‡†å¯¹æ¯”ï¼ˆE_Layer=1, D_Layer=1ï¼‰
    baseline_key = (1, 1)
    if baseline_key in layer_combo_stats:
        baseline_mse = np.mean([s['mse'] for s in layer_combo_stats[baseline_key]])
        best_mse = sorted_results[0].get('test_mse', float('inf'))
        improvement = ((baseline_mse - best_mse) / baseline_mse) * 100
        print(f"\nä¸åŸºå‡† (E_Layer=1, D_Layer=1) å¯¹æ¯”:")
        print(f"  åŸºå‡†MSE: {baseline_mse:.6f}")
        print(f"  æœ€ä½³MSE: {best_mse:.6f}")
        if improvement > 0:
            print(f"  æ”¹è¿›å¹…åº¦: {improvement:.2f}% (é™ä½)")
        else:
            print(f"  å˜åŒ–å¹…åº¦: {abs(improvement):.2f}% (å¢åŠ )")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='åˆ†æç¼–ç å™¨å’Œè§£ç å™¨å±‚æ•°å¯»ä¼˜å®éªŒç»“æœ')
    parser.add_argument('--result_file', type=str, default=None, help='ç»“æœæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: experiment_results.logï¼‰')
    parser.add_argument('--seed', type=int, default=2088, help='éšæœºç§å­')
    parser.add_argument('--model_id_prefix', type=str, default='T3Time_FreTS_Gated_Qwen_LayerSearch', 
                       help='æ¨¡å‹IDå‰ç¼€')
    
    args = parser.parse_args()
    
    results = load_layer_search_results(args.result_file, args.seed, args.model_id_prefix)
    
    if not results:
        print(f"\nâŒ æœªæ‰¾åˆ° seed={args.seed} çš„å±‚æ•°å¯»ä¼˜å®éªŒç»“æœ")
        print("è¯·å…ˆè¿è¡Œå±‚æ•°å¯»ä¼˜è„šæœ¬: bash scripts/T3Time_FreTS_FusionExp/hyperopt_layer_search.sh")
        return
    
    sorted_results, e_layer_stats, d_layer_stats, layer_combo_stats = analyze_layer_impact(results)
    print_analysis(sorted_results, e_layer_stats, d_layer_stats, layer_combo_stats)
    
    print("\n" + "="*80)
    print("åˆ†æå®Œæˆï¼")
    print("="*80)

if __name__ == "__main__":
    main()

#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯¹æ¯”æœ€ä½³MSEå’Œæœ€ä½³MAEå‚æ•°ç»„åˆçš„å·®å¼‚
"""
import json
import os
import sys
from collections import defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

def load_hyperopt_results(result_file=None, seed=2088, pred_len=720, model_id_prefix="T3Time_FreTS_Gated_Qwen_Hyperopt"):
    """åŠ è½½å‚æ•°å¯»ä¼˜å®éªŒç»“æœ"""
    if result_file is None:
        result_file = os.path.join(project_root, "experiment_results.log")
    
    results = []
    
    if not os.path.exists(result_file):
        print(f"âŒ ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {result_file}")
        return results
    
    with open(result_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            if not line.strip():
                continue
            try:
                data = json.loads(line.strip())
                # æ£€æŸ¥æ˜¯å¦æ˜¯å‚æ•°å¯»ä¼˜å®éªŒç»“æœ
                if (data.get('seed') == seed and 
                    data.get('pred_len') == pred_len and
                    data.get('model_id', '').startswith(model_id_prefix)):
                    results.append(data)
            except json.JSONDecodeError as e:
                continue
            except Exception as e:
                continue
    
    return results

def compare_best_mse_mae(results):
    """å¯¹æ¯”æœ€ä½³MSEå’Œæœ€ä½³MAEå‚æ•°ç»„åˆ"""
    if not results:
        return None, None
    
    # æŒ‰ MSE æ’åº
    sorted_results_mse = sorted(results, key=lambda x: x.get('test_mse', float('inf')))
    best_mse = sorted_results_mse[0] if sorted_results_mse else None
    
    # æŒ‰ MAE æ’åº
    sorted_results_mae = sorted(results, key=lambda x: x.get('test_mae', float('inf')))
    best_mae = sorted_results_mae[0] if sorted_results_mae else None
    
    return best_mse, best_mae

def print_comparison(best_mse, best_mae, pred_len=720):
    """æ‰“å°å¯¹æ¯”ç»“æœ"""
    print("="*80)
    print(f"ğŸ“Š é¢„æµ‹é•¿åº¦ {pred_len} - æœ€ä½³MSE vs æœ€ä½³MAE å‚æ•°å¯¹æ¯”")
    print("="*80)
    
    if not best_mse or not best_mae:
        print("âŒ æœªæ‰¾åˆ°å®éªŒç»“æœ")
        return
    
    # å®šä¹‰æ‰€æœ‰è¦å¯¹æ¯”çš„å‚æ•°
    params_to_compare = [
        ('data_path', 'æ•°æ®è·¯å¾„'),
        ('seq_len', 'åºåˆ—é•¿åº¦'),
        ('pred_len', 'é¢„æµ‹é•¿åº¦'),
        ('channel', 'Channel'),
        ('head', 'Head'),
        ('e_layer', 'E_Layer'),
        ('d_layer', 'D_Layer'),
        ('learning_rate', 'å­¦ä¹ ç‡'),
        ('weight_decay', 'æƒé‡è¡°å‡'),
        ('dropout_n', 'Dropout'),
        ('batch_size', 'æ‰¹æ¬¡å¤§å°'),
        ('loss_fn', 'æŸå¤±å‡½æ•°'),
        ('lradj', 'å­¦ä¹ ç‡è°ƒæ•´'),
        ('embed_version', 'åµŒå…¥ç‰ˆæœ¬'),
        ('epochs', 'è®­ç»ƒè½®æ•°'),
        ('patience', 'æ—©åœè€å¿ƒ'),
        ('seed', 'éšæœºç§å­'),
    ]
    
    # æ‰“å°å‚æ•°å¯¹æ¯”è¡¨
    print("\n" + "="*80)
    print("å‚æ•°å¯¹æ¯”è¡¨")
    print("="*80)
    print(f"{'å‚æ•°åç§°':<20} {'æœ€ä½³MSEå€¼':<25} {'æœ€ä½³MAEå€¼':<25} {'æ˜¯å¦ç›¸åŒ':<10}")
    print("-"*80)
    
    differences = []
    for param_key, param_name in params_to_compare:
        mse_value = best_mse.get(param_key, 'N/A')
        mae_value = best_mae.get(param_key, 'N/A')
        
        # å¤„ç†æµ®ç‚¹æ•°æ¯”è¾ƒ
        if isinstance(mse_value, float) and isinstance(mae_value, float):
            is_same = abs(mse_value - mae_value) < 1e-10
        else:
            is_same = mse_value == mae_value
        
        same_str = "âœ“ ç›¸åŒ" if is_same else "âœ— ä¸åŒ"
        
        # æ ¼å¼åŒ–æ˜¾ç¤º
        if isinstance(mse_value, float):
            mse_str = f"{mse_value:.6f}" if mse_value < 1 else f"{mse_value:.2e}"
        else:
            mse_str = str(mse_value)
        
        if isinstance(mae_value, float):
            mae_str = f"{mae_value:.6f}" if mae_value < 1 else f"{mae_value:.2e}"
        else:
            mae_str = str(mae_value)
        
        print(f"{param_name:<20} {mse_str:<25} {mae_str:<25} {same_str:<10}")
        
        if not is_same:
            differences.append((param_name, mse_value, mae_value))
    
    # æ‰“å°ç»“æœæŒ‡æ ‡å¯¹æ¯”
    print("\n" + "="*80)
    print("ç»“æœæŒ‡æ ‡å¯¹æ¯”")
    print("="*80)
    print(f"{'æŒ‡æ ‡':<15} {'æœ€ä½³MSEç»„åˆ':<20} {'æœ€ä½³MAEç»„åˆ':<20} {'å·®å¼‚':<15}")
    print("-"*80)
    
    mse_mse = best_mse.get('test_mse', 0)
    mse_mae = best_mse.get('test_mae', 0)
    mae_mse = best_mae.get('test_mse', 0)
    mae_mae = best_mae.get('test_mae', 0)
    
    print(f"{'Test MSE':<15} {mse_mse:<20.6f} {mae_mse:<20.6f} {mae_mse - mse_mse:<15.6f}")
    print(f"{'Test MAE':<15} {mse_mae:<20.6f} {mae_mae:<20.6f} {mae_mae - mse_mae:<15.6f}")
    
    # æ‰“å°å·®å¼‚æ€»ç»“
    print("\n" + "="*80)
    print("å·®å¼‚æ€»ç»“")
    print("="*80)
    
    if not differences:
        print("âœ“ ä¸¤ä¸ªå‚æ•°ç»„åˆå®Œå…¨ç›¸åŒï¼")
    else:
        print(f"å‘ç° {len(differences)} ä¸ªå‚æ•°ä¸åŒï¼š\n")
        for param_name, mse_value, mae_value in differences:
            print(f"  â€¢ {param_name}:")
            print(f"    - æœ€ä½³MSEç»„åˆ: {mse_value}")
            print(f"    - æœ€ä½³MAEç»„åˆ: {mae_value}")
            if isinstance(mse_value, float) and isinstance(mae_value, float):
                diff = abs(mae_value - mse_value)
                diff_pct = (diff / mse_value * 100) if mse_value != 0 else 0
                print(f"    - å·®å¼‚: {diff:.6e} ({diff_pct:.2f}%)")
            print()
    
    # è§£é‡Šä¸ºä»€ä¹ˆä¼šæœ‰å·®å¼‚
    print("="*80)
    print("ğŸ’¡ ä¸ºä»€ä¹ˆä¼šæœ‰å·®å¼‚ï¼Ÿ")
    print("="*80)
    print("""
1. **ä¼˜åŒ–ç›®æ ‡ä¸åŒ**ï¼š
   - æœ€ä½³MSEç»„åˆï¼šä¼˜åŒ–çš„æ˜¯å‡æ–¹è¯¯å·®ï¼ˆMSEï¼‰ï¼Œå¯¹å¤§è¯¯å·®æ›´æ•æ„Ÿ
   - æœ€ä½³MAEç»„åˆï¼šä¼˜åŒ–çš„æ˜¯å¹³å‡ç»å¯¹è¯¯å·®ï¼ˆMAEï¼‰ï¼Œå¯¹æ‰€æœ‰è¯¯å·®åŒç­‰å¯¹å¾…

2. **å‚æ•°å½±å“**ï¼š
   - å­¦ä¹ ç‡ï¼ˆlearning_rateï¼‰å’Œæƒé‡è¡°å‡ï¼ˆweight_decayï¼‰æ˜¯æ­£åˆ™åŒ–å‚æ•°
   - ä¸åŒçš„ä¼˜åŒ–ç›®æ ‡å¯èƒ½éœ€è¦ä¸åŒçš„æ­£åˆ™åŒ–å¼ºåº¦
   - MSEæ›´å…³æ³¨å¤§è¯¯å·®ï¼Œå¯èƒ½éœ€è¦æ›´å¼ºçš„æ­£åˆ™åŒ–ï¼ˆæ›´é«˜çš„weight_decayï¼‰
   - MAEå¯¹æ‰€æœ‰è¯¯å·®åŒç­‰å¯¹å¾…ï¼Œå¯èƒ½éœ€è¦æ›´æ¸©å’Œçš„æ­£åˆ™åŒ–

3. **å®é™…æ„ä¹‰**ï¼š
   - å¦‚æœæ›´å…³æ³¨æ•´ä½“é¢„æµ‹ç²¾åº¦ï¼Œä½¿ç”¨æœ€ä½³MSEç»„åˆ
   - å¦‚æœæ›´å…³æ³¨é¿å…æç«¯è¯¯å·®ï¼Œä½¿ç”¨æœ€ä½³MAEç»„åˆ
   - ä¸¤ä¸ªç»„åˆçš„æ¶æ„å‚æ•°ï¼ˆchannel, head, e_layer, d_layerï¼‰ç›¸åŒï¼Œè¯´æ˜æ¨¡å‹ç»“æ„æ˜¯ç¨³å®šçš„
    """)
    
    # æ‰“å°å‘½ä»¤è¡Œæ ¼å¼å¯¹æ¯”
    print("\n" + "="*80)
    print("å‘½ä»¤è¡Œæ ¼å¼å¯¹æ¯”ï¼ˆä»…æ˜¾ç¤ºä¸åŒå‚æ•°ï¼‰")
    print("="*80)
    
    print("\nã€æœ€ä½³MSEç»„åˆã€‘")
    print("python train_frets_gated_qwen.py \\")
    print(f"    --data_path {best_mse.get('data_path', 'ETTh1')} \\")
    print(f"    --seq_len {best_mse.get('seq_len', 96)} \\")
    print(f"    --pred_len {best_mse.get('pred_len', 720)} \\")
    print(f"    --channel {best_mse.get('channel', 'N/A')} \\")
    print(f"    --head {best_mse.get('head', 'N/A')} \\")
    print(f"    --e_layer {best_mse.get('e_layer', 1)} \\")
    print(f"    --d_layer {best_mse.get('d_layer', 1)} \\")
    print(f"    --learning_rate {best_mse.get('learning_rate', 'N/A')} \\  # âš ï¸ ä¸MAEä¸åŒ")
    print(f"    --weight_decay {best_mse.get('weight_decay', 'N/A')} \\  # âš ï¸ ä¸MAEä¸åŒ")
    print(f"    --dropout_n {best_mse.get('dropout_n', 'N/A')} \\")
    print(f"    --batch_size {best_mse.get('batch_size', 'N/A')} \\")
    print(f"    --loss_fn {best_mse.get('loss_fn', 'N/A')} \\")
    print(f"    --lradj {best_mse.get('lradj', 'type1')} \\")
    print(f"    --embed_version {best_mse.get('embed_version', 'qwen3_0.6b')} \\")
    print(f"    --epochs {best_mse.get('epochs', 100)} \\")
    print(f"    --es_patience {best_mse.get('patience', 10)} \\")
    print(f"    --seed {best_mse.get('seed', 2088)}")
    
    print("\nã€æœ€ä½³MAEç»„åˆã€‘")
    print("python train_frets_gated_qwen.py \\")
    print(f"    --data_path {best_mae.get('data_path', 'ETTh1')} \\")
    print(f"    --seq_len {best_mae.get('seq_len', 96)} \\")
    print(f"    --pred_len {best_mae.get('pred_len', 720)} \\")
    print(f"    --channel {best_mae.get('channel', 'N/A')} \\")
    print(f"    --head {best_mae.get('head', 'N/A')} \\")
    print(f"    --e_layer {best_mae.get('e_layer', 1)} \\")
    print(f"    --d_layer {best_mae.get('d_layer', 1)} \\")
    print(f"    --learning_rate {best_mae.get('learning_rate', 'N/A')} \\  # âš ï¸ ä¸MSEä¸åŒ")
    print(f"    --weight_decay {best_mae.get('weight_decay', 'N/A')} \\  # âš ï¸ ä¸MAEä¸åŒ")
    print(f"    --dropout_n {best_mae.get('dropout_n', 'N/A')} \\")
    print(f"    --batch_size {best_mae.get('batch_size', 'N/A')} \\")
    print(f"    --loss_fn {best_mae.get('loss_fn', 'N/A')} \\")
    print(f"    --lradj {best_mae.get('lradj', 'type1')} \\")
    print(f"    --embed_version {best_mae.get('embed_version', 'qwen3_0.6b')} \\")
    print(f"    --epochs {best_mae.get('epochs', 100)} \\")
    print(f"    --es_patience {best_mae.get('patience', 10)} \\")
    print(f"    --seed {best_mae.get('seed', 2088)}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å¯¹æ¯”æœ€ä½³MSEå’Œæœ€ä½³MAEå‚æ•°ç»„åˆçš„å·®å¼‚')
    parser.add_argument('--result_file', type=str, default=None, help='ç»“æœæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: experiment_results.logï¼‰')
    parser.add_argument('--seed', type=int, default=2088, help='éšæœºç§å­')
    parser.add_argument('--pred_len', type=int, default=720, help='é¢„æµ‹é•¿åº¦')
    parser.add_argument('--model_id_prefix', type=str, default='T3Time_FreTS_Gated_Qwen_Hyperopt', 
                       help='æ¨¡å‹IDå‰ç¼€')
    
    args = parser.parse_args()
    
    results = load_hyperopt_results(args.result_file, args.seed, args.pred_len, args.model_id_prefix)
    
    if not results:
        print(f"\nâŒ æœªæ‰¾åˆ° seed={args.seed}, pred_len={args.pred_len} çš„å‚æ•°å¯»ä¼˜å®éªŒç»“æœ")
        return
    
    best_mse, best_mae = compare_best_mse_mae(results)
    print_comparison(best_mse, best_mae, args.pred_len)
    
    print("\n" + "="*80)
    print("å¯¹æ¯”å®Œæˆï¼")
    print("="*80)

if __name__ == "__main__":
    main()

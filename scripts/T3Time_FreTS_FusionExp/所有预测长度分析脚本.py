#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ£€ç´¢ T3Time_FreTS_FusionExp æ¨¡å‹çš„æ‰€æœ‰ç§å­çš„å‚æ•°å¯»ä¼˜å®éªŒç»“æœ
æŒ‰é¢„æµ‹é•¿åº¦ï¼ˆ96, 192, 336, 720ï¼‰åˆ†åˆ«åˆ†æ
æ”¯æŒåˆ†ææ‰€æœ‰ç§å­æˆ–æŒ‡å®šç§å­çš„å®éªŒç»“æœ
"""
import json
import os
import sys
from collections import defaultdict

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.abspath(os.path.join(os.path.dirname(__file__), '..', '..'))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

def load_hyperopt_results(result_file=None, seed=None, model_id_prefix="T3Time_FreTS_Gated_Qwen_Hyperopt",
                          data_path=None):
    """
    åŠ è½½å‚æ•°å¯»ä¼˜å®éªŒç»“æœ
    
    Args:
        result_file: ç»“æœæ–‡ä»¶è·¯å¾„ï¼Œé»˜è®¤ä¸º experiment_results.log
        seed: éšæœºç§å­ï¼Œå¦‚æœä¸º None åˆ™åŠ è½½æ‰€æœ‰ç§å­çš„ç»“æœ
        model_id_prefix: æ¨¡å‹IDå‰ç¼€
        data_path: æ•°æ®é›†åç§°ï¼ˆä¾‹å¦‚ 'ETTh1'ï¼‰ã€‚å¦‚æœä¸º None åˆ™ä¸è¿‡æ»¤æ•°æ®é›†ã€‚
    """
    if result_file is None:
        result_file = os.path.join(project_root, "experiment_results.log")
    
    results = []
    
    if not os.path.exists(result_file):
        print(f"âŒ ç»“æœæ–‡ä»¶ä¸å­˜åœ¨: {result_file}")
        return results
    
    with open(result_file, 'r', encoding='utf-8') as f:
        for line_num, line in enumerate(f, 1):
            if not line.strip():
                continue
            try:
                data = json.loads(line.strip())
                # æ£€æŸ¥æ˜¯å¦æ˜¯å‚æ•°å¯»ä¼˜å®éªŒç»“æœ
                if not data.get('model_id', '').startswith(model_id_prefix):
                    continue

                # å¦‚æœæŒ‡å®šäº†æ•°æ®é›†ï¼Œåˆ™åªä¿ç•™è¯¥æ•°æ®é›†çš„ç»“æœ
                if data_path is not None:
                    # éƒ¨åˆ†æ—¥å¿—å¯èƒ½ä½¿ç”¨ 'data' æˆ– 'data_path' ä½œä¸ºé”®ï¼Œè¿™é‡Œç»Ÿä¸€å…¼å®¹
                    log_data_path = data.get('data_path', data.get('data'))
                    if log_data_path != data_path:
                        continue

                # å¦‚æœæŒ‡å®šäº† seedï¼Œåˆ™åªåŠ è½½è¯¥ seed çš„ç»“æœï¼›å¦åˆ™åŠ è½½æ‰€æœ‰ seed
                if seed is None or data.get('seed') == seed:
                    results.append(data)
            except json.JSONDecodeError as e:
                continue
            except Exception as e:
                continue
    
    return results

def find_best_params_by_pred_len(results, pred_lens=[96, 192, 336, 720]):
    """æŒ‰é¢„æµ‹é•¿åº¦åˆ†ç»„ï¼Œæ‰¾å‡ºæ¯ä¸ªé¢„æµ‹é•¿åº¦çš„æœ€ä½³å‚æ•°ç»„åˆ"""
    if not results:
        return {}
    
    results_by_pred_len = {}
    
    for pred_len in pred_lens:
        # ç­›é€‰è¯¥é¢„æµ‹é•¿åº¦çš„ç»“æœ
        pred_results = [r for r in results if r.get('pred_len') == pred_len]
        
        if not pred_results:
            results_by_pred_len[pred_len] = {
                'best_mse': None,
                'best_mae': None,
                'sorted_results_mse': [],
                'sorted_results_mae': [],
                'param_avg': {},
                'count': 0
            }
            continue
        
        # æŒ‰ MSE æ’åº
        sorted_results_mse = sorted(pred_results, key=lambda x: x.get('test_mse', float('inf')))
        best_mse = sorted_results_mse[0] if sorted_results_mse else None
        
        # æŒ‰ MAE æ’åº
        sorted_results_mae = sorted(pred_results, key=lambda x: x.get('test_mae', float('inf')))
        best_mae = sorted_results_mae[0] if sorted_results_mae else None
        
        # ç»Ÿè®¡æ¯ä¸ªå‚æ•°ç»„åˆçš„MSEå’ŒMAE
        param_stats_mse = defaultdict(list)
        param_stats_mae = defaultdict(list)
        for r in pred_results:
            param_key = (r.get('channel'), r.get('dropout_n'), r.get('head'))
            param_stats_mse[param_key].append(r.get('test_mse', float('inf')))
            param_stats_mae[param_key].append(r.get('test_mae', float('inf')))
        
        # è®¡ç®—æ¯ä¸ªå‚æ•°ç»„åˆçš„å¹³å‡ MSE å’Œ MAE
        param_avg = {}
        for param_key in param_stats_mse.keys():
            mse_list = param_stats_mse[param_key]
            mae_list = param_stats_mae[param_key]
            param_avg[param_key] = {
                'mse_mean': sum(mse_list) / len(mse_list),
                'mse_min': min(mse_list),
                'mse_max': max(mse_list),
                'mae_mean': sum(mae_list) / len(mae_list),
                'mae_min': min(mae_list),
                'mae_max': max(mae_list),
                'count': len(mse_list)
            }
        
        results_by_pred_len[pred_len] = {
            'best_mse': best_mse,
            'best_mae': best_mae,
            'sorted_results_mse': sorted_results_mse,
            'sorted_results_mae': sorted_results_mae,
            'param_avg': param_avg,
            'count': len(pred_results)
        }
    
    return results_by_pred_len

def get_seed_statistics(results):
    """ç»Ÿè®¡æ‰€æœ‰ç»“æœçš„ç§å­åˆ†å¸ƒ"""
    seed_counts = defaultdict(int)
    seed_by_pred_len = defaultdict(lambda: defaultdict(int))
    
    for r in results:
        seed = r.get('seed', 'Unknown')
        pred_len = r.get('pred_len', 'Unknown')
        seed_counts[seed] += 1
        seed_by_pred_len[pred_len][seed] += 1
    
    return seed_counts, seed_by_pred_len

def print_results_by_pred_len(results_by_pred_len, pred_lens=[96, 192, 336, 720], all_results=None):
    """æŒ‰é¢„æµ‹é•¿åº¦æ‰“å°ç»“æœ"""
    print("="*80)
    print("T3Time_FreTS_Gated_Qwen å‚æ•°å¯»ä¼˜ç»“æœåˆ†æï¼ˆæ‰€æœ‰ç§å­ï¼‰")
    print("æŒ‰é¢„æµ‹é•¿åº¦åˆ†åˆ«åˆ†æ: {}".format(", ".join(map(str, pred_lens))))
    print("="*80)
    
    # ç»Ÿè®¡æ€»ç»“æœæ•°å’Œç§å­åˆ†å¸ƒ
    total_results = sum(data['count'] for data in results_by_pred_len.values())
    
    if all_results:
        seed_counts, seed_by_pred_len_stats = get_seed_statistics(all_results)
        print(f"\næ‰¾åˆ° {total_results} æ¡å®éªŒç»“æœ")
        print(f"æ¶‰åŠ {len(seed_counts)} ä¸ªä¸åŒçš„ç§å­: {sorted(seed_counts.keys())}")
        print("\nç§å­åˆ†å¸ƒç»Ÿè®¡:")
        print(f"{'Seed':<10} {'æ€»å®éªŒæ•°':<12}")
        print("-"*25)
        for seed in sorted(seed_counts.keys()):
            print(f"{seed:<10} {seed_counts[seed]:<12}")
    else:
        print(f"\næ‰¾åˆ° {total_results} æ¡å®éªŒç»“æœ\n")
    
    # å¯¹æ¯ä¸ªé¢„æµ‹é•¿åº¦åˆ†åˆ«åˆ†æ
    for pred_len in pred_lens:
        data = results_by_pred_len.get(pred_len, {})
        best_mse = data.get('best_mse')
        best_mae = data.get('best_mae')
        sorted_results_mse = data.get('sorted_results_mse', [])
        sorted_results_mae = data.get('sorted_results_mae', [])
        param_avg = data.get('param_avg', {})
        count = data.get('count', 0)
        
        if not best_mse or not best_mae:
            print("\n" + "="*80)
            print(f"é¢„æµ‹é•¿åº¦ {pred_len}: æœªæ‰¾åˆ°å®éªŒç»“æœ")
            print("="*80)
            continue
        
        print("\n" + "="*80)
        print(f"ğŸ“Š é¢„æµ‹é•¿åº¦ {pred_len} (å…± {count} æ¡å®éªŒç»“æœ)")
        print("="*80)
        
        # æ‰“å°è¯¥é¢„æµ‹é•¿åº¦çš„æœ€ä½³ç»“æœ
        print_single_pred_len_results(best_mse, best_mae, sorted_results_mse, sorted_results_mae, param_avg, pred_len)

def print_single_pred_len_results(best_mse, best_mae, sorted_results_mse, sorted_results_mae, param_avg, pred_len):
    """æ‰“å°å•ä¸ªé¢„æµ‹é•¿åº¦çš„ç»“æœ"""
    
    # æœ€å°MSEæœ€ä½³ç»“æœï¼ˆæ˜¾ç¤ºæ‰€æœ‰è¯¦ç»†å‚æ•°ï¼‰
    print("\n" + "="*80)
    print(f"ğŸ† é¢„æµ‹é•¿åº¦ {pred_len} - æœ€å° MSE å‚æ•°ç»„åˆï¼ˆå®Œæ•´å‚æ•°ï¼‰")
    print("="*80)
    print("ã€æ¶æ„å‚æ•°ã€‘")
    print(f"  Channel:        {best_mse.get('channel', 'N/A')}")
    print(f"  Head:           {best_mse.get('head', 'N/A')}")
    print(f"  E_Layer:        {best_mse.get('e_layer', 'N/A')}")
    print(f"  D_Layer:        {best_mse.get('d_layer', 'N/A')}")
    print("")
    print("ã€è®­ç»ƒå‚æ•°ã€‘")
    print(f"  Learning_Rate:  {best_mse.get('learning_rate', 'N/A')}")
    print(f"  Weight_Decay:   {best_mse.get('weight_decay', 'N/A')}")
    print(f"  Dropout:        {best_mse.get('dropout_n', 'N/A')}")
    print(f"  Batch_Size:     {best_mse.get('batch_size', 'N/A')}")
    print(f"  Loss_Function:  {best_mse.get('loss_fn', 'N/A')}")
    print(f"  LR_Adjust:      {best_mse.get('lradj', 'N/A')}")
    print("")
    print("ã€æ•°æ®å‚æ•°ã€‘")
    print(f"  Data_Path:      {best_mse.get('data_path', 'N/A')}")
    print(f"  Seq_Len:        {best_mse.get('seq_len', 'N/A')}")
    print(f"  Pred_Len:       {best_mse.get('pred_len', 'N/A')}")
    print(f"  Embed_Version:  {best_mse.get('embed_version', 'N/A')}")
    print("")
    print("ã€è®­ç»ƒé…ç½®ã€‘")
    print(f"  Epochs:         {best_mse.get('epochs', 'N/A')}")
    print(f"  Patience:       {best_mse.get('patience', 'N/A')}")
    print(f"  Seed:           {best_mse.get('seed', 'N/A')} â­")
    print("")
    print("ã€ç»“æœæŒ‡æ ‡ã€‘")
    print(f"  Test MSE:       {best_mse.get('test_mse', 'N/A'):.6f}")
    print(f"  Test MAE:       {best_mse.get('test_mae', 'N/A'):.6f}")
    print("")
    print("ã€å…¶ä»–ä¿¡æ¯ã€‘")
    print(f"  Model_ID:       {best_mse.get('model_id', 'N/A')}")
    print(f"  Timestamp:      {best_mse.get('timestamp', 'N/A')}")
    
    # æœ€å°MAEæœ€ä½³ç»“æœï¼ˆæ˜¾ç¤ºæ‰€æœ‰è¯¦ç»†å‚æ•°ï¼‰
    print("\n" + "="*80)
    print(f"ğŸ† é¢„æµ‹é•¿åº¦ {pred_len} - æœ€å° MAE å‚æ•°ç»„åˆï¼ˆå®Œæ•´å‚æ•°ï¼‰")
    print("="*80)
    print("ã€æ¶æ„å‚æ•°ã€‘")
    print(f"  Channel:        {best_mae.get('channel', 'N/A')}")
    print(f"  Head:           {best_mae.get('head', 'N/A')}")
    print(f"  E_Layer:        {best_mae.get('e_layer', 'N/A')}")
    print(f"  D_Layer:        {best_mae.get('d_layer', 'N/A')}")
    print("")
    print("ã€è®­ç»ƒå‚æ•°ã€‘")
    print(f"  Learning_Rate:  {best_mae.get('learning_rate', 'N/A')}")
    print(f"  Weight_Decay:   {best_mae.get('weight_decay', 'N/A')}")
    print(f"  Dropout:        {best_mae.get('dropout_n', 'N/A')}")
    print(f"  Batch_Size:     {best_mae.get('batch_size', 'N/A')}")
    print(f"  Loss_Function:  {best_mae.get('loss_fn', 'N/A')}")
    print(f"  LR_Adjust:      {best_mae.get('lradj', 'N/A')}")
    print("")
    print("ã€æ•°æ®å‚æ•°ã€‘")
    print(f"  Data_Path:      {best_mae.get('data_path', 'N/A')}")
    print(f"  Seq_Len:        {best_mae.get('seq_len', 'N/A')}")
    print(f"  Pred_Len:       {best_mae.get('pred_len', 'N/A')}")
    print(f"  Embed_Version:  {best_mae.get('embed_version', 'N/A')}")
    print("")
    print("ã€è®­ç»ƒé…ç½®ã€‘")
    print(f"  Epochs:         {best_mae.get('epochs', 'N/A')}")
    print(f"  Patience:       {best_mae.get('patience', 'N/A')}")
    print(f"  Seed:           {best_mae.get('seed', 'N/A')} â­")
    print("")
    print("ã€ç»“æœæŒ‡æ ‡ã€‘")
    print(f"  Test MSE:       {best_mae.get('test_mse', 'N/A'):.6f}")
    print(f"  Test MAE:       {best_mae.get('test_mae', 'N/A'):.6f}")
    print("")
    print("ã€å…¶ä»–ä¿¡æ¯ã€‘")
    print(f"  Model_ID:       {best_mae.get('model_id', 'N/A')}")
    print(f"  Timestamp:      {best_mae.get('timestamp', 'N/A')}")
    
    # æ·»åŠ å‘½ä»¤è¡Œå‚æ•°æ ¼å¼ï¼Œæ–¹ä¾¿ç›´æ¥ä½¿ç”¨
    print("\n" + "="*80)
    print(f"ğŸ“‹ é¢„æµ‹é•¿åº¦ {pred_len} - æœ€ä½³ MSE å‚æ•°ç»„åˆï¼ˆå‘½ä»¤è¡Œæ ¼å¼ï¼‰")
    print("="*80)
    print("python train_frets_gated_qwen.py \\")
    print(f"    --data_path {best_mse.get('data_path', 'ETTh1')} \\")
    print(f"    --seq_len {best_mse.get('seq_len', 96)} \\")
    print(f"    --pred_len {best_mse.get('pred_len', 96)} \\")
    print(f"    --channel {best_mse.get('channel', 'N/A')} \\")
    print(f"    --head {best_mse.get('head', 'N/A')} \\")
    print(f"    --e_layer {best_mse.get('e_layer', 1)} \\")
    print(f"    --d_layer {best_mse.get('d_layer', 1)} \\")
    print(f"    --learning_rate {best_mse.get('learning_rate', 'N/A')} \\")
    print(f"    --weight_decay {best_mse.get('weight_decay', 'N/A')} \\")
    print(f"    --dropout_n {best_mse.get('dropout_n', 'N/A')} \\")
    print(f"    --batch_size {best_mse.get('batch_size', 'N/A')} \\")
    print(f"    --loss_fn {best_mse.get('loss_fn', 'N/A')} \\")
    print(f"    --lradj {best_mse.get('lradj', 'type1')} \\")
    print(f"    --embed_version {best_mse.get('embed_version', 'qwen3_0.6b')} \\")
    print(f"    --epochs {best_mse.get('epochs', 100)} \\")
    print(f"    --es_patience {best_mse.get('patience', 10)} \\")
    print(f"    --seed {best_mse.get('seed', 2088)}")
    
    print("\n" + "="*80)
    print(f"ğŸ“‹ é¢„æµ‹é•¿åº¦ {pred_len} - æœ€ä½³ MAE å‚æ•°ç»„åˆï¼ˆå‘½ä»¤è¡Œæ ¼å¼ï¼‰")
    print("="*80)
    print("python train_frets_gated_qwen.py \\")
    print(f"    --data_path {best_mae.get('data_path', 'ETTh1')} \\")
    print(f"    --seq_len {best_mae.get('seq_len', 96)} \\")
    print(f"    --pred_len {best_mae.get('pred_len', 96)} \\")
    print(f"    --channel {best_mae.get('channel', 'N/A')} \\")
    print(f"    --head {best_mae.get('head', 'N/A')} \\")
    print(f"    --e_layer {best_mae.get('e_layer', 1)} \\")
    print(f"    --d_layer {best_mae.get('d_layer', 1)} \\")
    print(f"    --learning_rate {best_mae.get('learning_rate', 'N/A')} \\")
    print(f"    --weight_decay {best_mae.get('weight_decay', 'N/A')} \\")
    print(f"    --dropout_n {best_mae.get('dropout_n', 'N/A')} \\")
    print(f"    --batch_size {best_mae.get('batch_size', 'N/A')} \\")
    print(f"    --loss_fn {best_mae.get('loss_fn', 'N/A')} \\")
    print(f"    --lradj {best_mae.get('lradj', 'type1')} \\")
    print(f"    --embed_version {best_mae.get('embed_version', 'qwen3_0.6b')} \\")
    print(f"    --epochs {best_mae.get('epochs', 100)} \\")
    print(f"    --es_patience {best_mae.get('patience', 10)} \\")
    print(f"    --seed {best_mae.get('seed', 2088)}")
    
    # Top 10 æœ€ä½³ç»“æœï¼ˆæŒ‰MSEï¼‰
    print("\n" + "="*80)
    print(f"é¢„æµ‹é•¿åº¦ {pred_len} - Top 10 æœ€ä½³é…ç½®ï¼ˆæŒ‰ MSE æ’åºï¼‰")
    print("="*80)
    print(f"{'Rank':<6} {'Channel':<10} {'Dropout':<10} {'Head':<8} {'MSE':<15} {'MAE':<15}")
    print("-"*80)
    
    for i, r in enumerate(sorted_results_mse[:10], 1):
        print(f"{i:<6} {r.get('channel', 'N/A'):<10} {r.get('dropout_n', 'N/A'):<10.1f} "
              f"{r.get('head', 'N/A'):<8} {r.get('test_mse', 'N/A'):<15.6f} {r.get('test_mae', 'N/A'):<15.6f}")
    
    # Top 10 æœ€ä½³ç»“æœï¼ˆæŒ‰MAEï¼‰
    print("\n" + "="*80)
    print(f"é¢„æµ‹é•¿åº¦ {pred_len} - Top 10 æœ€ä½³é…ç½®ï¼ˆæŒ‰ MAE æ’åºï¼‰")
    print("="*80)
    print(f"{'Rank':<6} {'Channel':<10} {'Dropout':<10} {'Head':<8} {'MSE':<15} {'MAE':<15}")
    print("-"*80)
    
    for i, r in enumerate(sorted_results_mae[:10], 1):
        print(f"{i:<6} {r.get('channel', 'N/A'):<10} {r.get('dropout_n', 'N/A'):<10.1f} "
              f"{r.get('head', 'N/A'):<8} {r.get('test_mse', 'N/A'):<15.6f} {r.get('test_mae', 'N/A'):<15.6f}")
    
    # å‚æ•°ç»Ÿè®¡åˆ†æï¼ˆæŒ‰MSEï¼‰
    print("\n" + "="*80)
    print(f"é¢„æµ‹é•¿åº¦ {pred_len} - å‚æ•°ç»Ÿè®¡åˆ†æï¼ˆæŒ‰å¹³å‡ MSE æ’åºï¼‰")
    print("="*80)
    print(f"{'Channel':<10} {'Dropout':<10} {'Head':<8} {'å¹³å‡MSE':<15} {'æœ€å°MSE':<15} {'æœ€å¤§MSE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    
    sorted_params_mse = sorted(param_avg.items(), key=lambda x: x[1]['mse_mean'])
    for (channel, dropout, head), stats in sorted_params_mse[:20]:  # æ˜¾ç¤ºå‰20ä¸ª
        print(f"{channel:<10} {dropout:<10.1f} {head:<8} "
              f"{stats['mse_mean']:<15.6f} {stats['mse_min']:<15.6f} {stats['mse_max']:<15.6f} {stats['count']:<8}")
    
    # å‚æ•°ç»Ÿè®¡åˆ†æï¼ˆæŒ‰MAEï¼‰
    print("\n" + "="*80)
    print(f"é¢„æµ‹é•¿åº¦ {pred_len} - å‚æ•°ç»Ÿè®¡åˆ†æï¼ˆæŒ‰å¹³å‡ MAE æ’åºï¼‰")
    print("="*80)
    print(f"{'Channel':<10} {'Dropout':<10} {'Head':<8} {'å¹³å‡MAE':<15} {'æœ€å°MAE':<15} {'æœ€å¤§MAE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    
    sorted_params_mae = sorted(param_avg.items(), key=lambda x: x[1]['mae_mean'])
    for (channel, dropout, head), stats in sorted_params_mae[:20]:  # æ˜¾ç¤ºå‰20ä¸ª
        print(f"{channel:<10} {dropout:<10.1f} {head:<8} "
              f"{stats['mae_mean']:<15.6f} {stats['mae_min']:<15.6f} {stats['mae_max']:<15.6f} {stats['count']:<8}")
    
    # å„å‚æ•°ç»´åº¦åˆ†æ
    print("\n" + "="*80)
    print(f"é¢„æµ‹é•¿åº¦ {pred_len} - å„å‚æ•°ç»´åº¦åˆ†æï¼ˆMSEï¼‰")
    print("="*80)
    
    # Channel åˆ†æï¼ˆMSEï¼‰
    channel_stats_mse = defaultdict(list)
    channel_stats_mae = defaultdict(list)
    for r in sorted_results_mse:
        channel_stats_mse[r.get('channel')].append(r.get('test_mse', float('inf')))
        channel_stats_mae[r.get('channel')].append(r.get('test_mae', float('inf')))
    
    print("\n[1] Channel å‚æ•°åˆ†æï¼ˆMSEï¼‰:")
    print(f"{'Channel':<10} {'å¹³å‡MSE':<15} {'æœ€å°MSE':<15} {'æœ€å¤§MSE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    for channel in sorted(channel_stats_mse.keys()):
        mse_list = channel_stats_mse[channel]
        print(f"{channel:<10} {sum(mse_list)/len(mse_list):<15.6f} "
              f"{min(mse_list):<15.6f} {max(mse_list):<15.6f} {len(mse_list):<8}")
    
    # Dropout åˆ†æï¼ˆMSEï¼‰
    dropout_stats_mse = defaultdict(list)
    dropout_stats_mae = defaultdict(list)
    for r in sorted_results_mse:
        dropout_stats_mse[r.get('dropout_n')].append(r.get('test_mse', float('inf')))
        dropout_stats_mae[r.get('dropout_n')].append(r.get('test_mae', float('inf')))
    
    print("\n[2] Dropout å‚æ•°åˆ†æï¼ˆMSEï¼‰:")
    print(f"{'Dropout':<10} {'å¹³å‡MSE':<15} {'æœ€å°MSE':<15} {'æœ€å¤§MSE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    for dropout in sorted(dropout_stats_mse.keys()):
        mse_list = dropout_stats_mse[dropout]
        print(f"{dropout:<10.1f} {sum(mse_list)/len(mse_list):<15.6f} "
              f"{min(mse_list):<15.6f} {max(mse_list):<15.6f} {len(mse_list):<8}")
    
    # Head åˆ†æï¼ˆMSEï¼‰
    head_stats_mse = defaultdict(list)
    head_stats_mae = defaultdict(list)
    for r in sorted_results_mse:
        head_stats_mse[r.get('head')].append(r.get('test_mse', float('inf')))
        head_stats_mae[r.get('head')].append(r.get('test_mae', float('inf')))
    
    print("\n[3] Head å‚æ•°åˆ†æï¼ˆMSEï¼‰:")
    print(f"{'Head':<10} {'å¹³å‡MSE':<15} {'æœ€å°MSE':<15} {'æœ€å¤§MSE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    for head in sorted(head_stats_mse.keys()):
        mse_list = head_stats_mse[head]
        print(f"{head:<10} {sum(mse_list)/len(mse_list):<15.6f} "
              f"{min(mse_list):<15.6f} {max(mse_list):<15.6f} {len(mse_list):<8}")
    
    # å„å‚æ•°ç»´åº¦åˆ†æï¼ˆMAEï¼‰
    print("\n" + "="*80)
    print(f"é¢„æµ‹é•¿åº¦ {pred_len} - å„å‚æ•°ç»´åº¦åˆ†æï¼ˆMAEï¼‰")
    print("="*80)
    
    print("\n[1] Channel å‚æ•°åˆ†æï¼ˆMAEï¼‰:")
    print(f"{'Channel':<10} {'å¹³å‡MAE':<15} {'æœ€å°MAE':<15} {'æœ€å¤§MAE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    for channel in sorted(channel_stats_mae.keys()):
        mae_list = channel_stats_mae[channel]
        print(f"{channel:<10} {sum(mae_list)/len(mae_list):<15.6f} "
              f"{min(mae_list):<15.6f} {max(mae_list):<15.6f} {len(mae_list):<8}")
    
    print("\n[2] Dropout å‚æ•°åˆ†æï¼ˆMAEï¼‰:")
    print(f"{'Dropout':<10} {'å¹³å‡MAE':<15} {'æœ€å°MAE':<15} {'æœ€å¤§MAE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    for dropout in sorted(dropout_stats_mae.keys()):
        mae_list = dropout_stats_mae[dropout]
        print(f"{dropout:<10.1f} {sum(mae_list)/len(mae_list):<15.6f} "
              f"{min(mae_list):<15.6f} {max(mae_list):<15.6f} {len(mae_list):<8}")
    
    print("\n[3] Head å‚æ•°åˆ†æï¼ˆMAEï¼‰:")
    print(f"{'Head':<10} {'å¹³å‡MAE':<15} {'æœ€å°MAE':<15} {'æœ€å¤§MAE':<15} {'æ¬¡æ•°':<8}")
    print("-"*80)
    for head in sorted(head_stats_mae.keys()):
        mae_list = head_stats_mae[head]
        print(f"{head:<10} {sum(mae_list)/len(mae_list):<15.6f} "
              f"{min(mae_list):<15.6f} {max(mae_list):<15.6f} {len(mae_list):<8}")
    
    # æœ€ä½³å‚æ•°ç»„åˆï¼ˆæŒ‰å¹³å‡MSEï¼‰
    if param_avg:
        best_param_avg_mse = min(param_avg.items(), key=lambda x: x[1]['mse_mean'])
        (best_channel_mse, best_dropout_mse, best_head_mse), best_stats_mse = best_param_avg_mse
        
        print("\n" + "="*80)
        print(f"é¢„æµ‹é•¿åº¦ {pred_len} - ğŸ† æœ€ä½³å‚æ•°ç»„åˆï¼ˆæŒ‰å¹³å‡ MSEï¼‰")
        print("="*80)
        print(f"Channel:     {best_channel_mse}")
        print(f"Dropout:     {best_dropout_mse}")
        print(f"Head:        {best_head_mse}")
        print(f"å¹³å‡ MSE:    {best_stats_mse['mse_mean']:.6f}")
        print(f"æœ€å° MSE:    {best_stats_mse['mse_min']:.6f}")
        print(f"æœ€å¤§ MSE:    {best_stats_mse['mse_max']:.6f}")
        print(f"å¹³å‡ MAE:    {best_stats_mse['mae_mean']:.6f}")
        print(f"æœ€å° MAE:    {best_stats_mse['mae_min']:.6f}")
        print(f"æœ€å¤§ MAE:    {best_stats_mse['mae_max']:.6f}")
        print(f"å®éªŒæ¬¡æ•°:    {best_stats_mse['count']}")
        
        # æœ€ä½³å‚æ•°ç»„åˆï¼ˆæŒ‰å¹³å‡MAEï¼‰
        best_param_avg_mae = min(param_avg.items(), key=lambda x: x[1]['mae_mean'])
        (best_channel_mae, best_dropout_mae, best_head_mae), best_stats_mae = best_param_avg_mae
        
        print("\n" + "="*80)
        print(f"é¢„æµ‹é•¿åº¦ {pred_len} - ğŸ† æœ€ä½³å‚æ•°ç»„åˆï¼ˆæŒ‰å¹³å‡ MAEï¼‰")
        print("="*80)
        print(f"Channel:     {best_channel_mae}")
        print(f"Dropout:     {best_dropout_mae}")
        print(f"Head:        {best_head_mae}")
        print(f"å¹³å‡ MSE:    {best_stats_mae['mse_mean']:.6f}")
        print(f"æœ€å° MSE:    {best_stats_mae['mse_min']:.6f}")
        print(f"æœ€å¤§ MSE:    {best_stats_mae['mse_max']:.6f}")
        print(f"å¹³å‡ MAE:    {best_stats_mae['mae_mean']:.6f}")
        print(f"æœ€å° MAE:    {best_stats_mae['mae_min']:.6f}")
        print(f"æœ€å¤§ MAE:    {best_stats_mae['mae_max']:.6f}")
        print(f"å®éªŒæ¬¡æ•°:    {best_stats_mae['count']}")

def print_summary_table(results_by_pred_len, pred_lens=[96, 192, 336, 720]):
    """æ‰“å°æ‰€æœ‰é¢„æµ‹é•¿åº¦çš„æ±‡æ€»è¡¨æ ¼"""
    print("\n" + "="*80)
    print("ğŸ“Š æ‰€æœ‰é¢„æµ‹é•¿åº¦çš„æœ€ä½³ç»“æœæ±‡æ€»ï¼ˆè·¨æ‰€æœ‰ç§å­ï¼‰")
    print("="*80)
    
    # MSE æ±‡æ€»ï¼ˆæ·»åŠ ç»¼åˆå‡å€¼ï¼‰
    print("\nã€æœ€å° MSE æ±‡æ€»ã€‘")
    print(f"{'Pred_Len':<12} {'Seed':<8} {'Channel':<10} {'Dropout':<10} {'Head':<8} {'LR':<12} {'WD':<12} {'BS':<8} {'MSE':<15} {'MAE':<15}")
    print("-"*110)
    
    mse_values = []
    mae_values = []
    
    for pred_len in pred_lens:
        data = results_by_pred_len.get(pred_len, {})
        best_mse = data.get('best_mse')
        if best_mse:
            seed = best_mse.get('seed', 'N/A')
            mse_val = best_mse.get('test_mse')
            mae_val = best_mse.get('test_mae')
            
            if mse_val is not None:
                mse_values.append(mse_val)
            if mae_val is not None:
                mae_values.append(mae_val)
            
            print(f"{pred_len:<12} {seed:<8} {best_mse.get('channel', 'N/A'):<10} "
                  f"{best_mse.get('dropout_n', 'N/A'):<10.1f} {best_mse.get('head', 'N/A'):<8} "
                  f"{best_mse.get('learning_rate', 'N/A'):<12} {best_mse.get('weight_decay', 'N/A'):<12} "
                  f"{best_mse.get('batch_size', 'N/A'):<8} "
                  f"{mse_val:<15.6f} {mae_val:<15.6f}")
        else:
            print(f"{pred_len:<12} {'N/A':<8} {'N/A':<10} {'N/A':<10} {'N/A':<8} {'N/A':<12} {'N/A':<12} {'N/A':<8} {'N/A':<15} {'N/A':<15}")
    
    # æ˜¾ç¤ºç»¼åˆå‡å€¼
    if mse_values and mae_values:
        mse_avg = sum(mse_values) / len(mse_values)
        mae_avg = sum(mae_values) / len(mae_values)
        print("-"*110)
        print(f"{'ç»¼åˆå‡å€¼':<12} {'':<8} {'':<10} {'':<10} {'':<8} {'':<12} {'':<12} {'':<8} "
              f"{mse_avg:<15.6f} {mae_avg:<15.6f}")
    
    # MAE æ±‡æ€»ï¼ˆæ·»åŠ ç»¼åˆå‡å€¼ï¼‰
    print("\nã€æœ€å° MAE æ±‡æ€»ã€‘")
    print(f"{'Pred_Len':<12} {'Seed':<8} {'Channel':<10} {'Dropout':<10} {'Head':<8} {'LR':<12} {'WD':<12} {'BS':<8} {'MSE':<15} {'MAE':<15}")
    print("-"*110)
    
    mse_values_mae = []
    mae_values_mae = []
    
    for pred_len in pred_lens:
        data = results_by_pred_len.get(pred_len, {})
        best_mae = data.get('best_mae')
        if best_mae:
            seed = best_mae.get('seed', 'N/A')
            mse_val = best_mae.get('test_mse')
            mae_val = best_mae.get('test_mae')
            
            if mse_val is not None:
                mse_values_mae.append(mse_val)
            if mae_val is not None:
                mae_values_mae.append(mae_val)
            
            print(f"{pred_len:<12} {seed:<8} {best_mae.get('channel', 'N/A'):<10} "
                  f"{best_mae.get('dropout_n', 'N/A'):<10.1f} {best_mae.get('head', 'N/A'):<8} "
                  f"{best_mae.get('learning_rate', 'N/A'):<12} {best_mae.get('weight_decay', 'N/A'):<12} "
                  f"{best_mae.get('batch_size', 'N/A'):<8} "
                  f"{mse_val:<15.6f} {mae_val:<15.6f}")
        else:
            print(f"{pred_len:<12} {'N/A':<8} {'N/A':<10} {'N/A':<10} {'N/A':<8} {'N/A':<12} {'N/A':<12} {'N/A':<8} {'N/A':<15} {'N/A':<15}")
    
    # æ˜¾ç¤ºç»¼åˆå‡å€¼
    if mse_values_mae and mae_values_mae:
        mse_avg_mae = sum(mse_values_mae) / len(mse_values_mae)
        mae_avg_mae = sum(mae_values_mae) / len(mae_values_mae)
        print("-"*110)
        print(f"{'ç»¼åˆå‡å€¼':<12} {'':<8} {'':<10} {'':<10} {'':<8} {'':<12} {'':<12} {'':<8} "
              f"{mse_avg_mae:<15.6f} {mae_avg_mae:<15.6f}")

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(
        description='æ£€ç´¢ T3Time_FreTS_FusionExp æ¨¡å‹çš„æ‰€æœ‰ç§å­çš„å‚æ•°å¯»ä¼˜å®éªŒç»“æœï¼ˆæŒ‰é¢„æµ‹é•¿åº¦åˆ†åˆ«åˆ†æï¼‰'
    )
    parser.add_argument('--result_file', type=str, default=None,
                        help='ç»“æœæ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤: experiment_results.logï¼‰')
    parser.add_argument('--seed', type=int, default=None,
                        help='éšæœºç§å­ï¼ˆé»˜è®¤: Noneï¼Œåˆ†ææ‰€æœ‰ç§å­ï¼‰')
    parser.add_argument('--model_id_prefix', type=str,
                        default='T3Time_FreTS_Gated_Qwen_Hyperopt',
                        help='æ¨¡å‹IDå‰ç¼€')
    parser.add_argument('--pred_lens', type=int, nargs='+',
                        default=[96, 192, 336, 720],
                        help='è¦åˆ†æçš„é¢„æµ‹é•¿åº¦åˆ—è¡¨ï¼ˆé»˜è®¤: 96 192 336 720ï¼‰')
    parser.add_argument('--data_path', type=str, default='ETTh1',
                        help='æ•°æ®é›†åç§°ï¼ˆé»˜è®¤: ETTh1ï¼›ä¾‹å¦‚: ETTh1, ETTh2, ETTm1, ETTm2ï¼‰')
    
    args = parser.parse_args()
    
    results = load_hyperopt_results(
        result_file=args.result_file,
        seed=args.seed,
        model_id_prefix=args.model_id_prefix,
        data_path=args.data_path,
    )
    
    if not results:
        if args.seed is None:
            print(f"\nâŒ æœªæ‰¾åˆ° {args.model_id_prefix} æ¨¡å‹çš„ä»»ä½•å®éªŒç»“æœ")
        else:
            print(f"\nâŒ æœªæ‰¾åˆ° seed={args.seed} çš„å‚æ•°å¯»ä¼˜å®éªŒç»“æœ")
        print("è¯·å…ˆè¿è¡Œå‚æ•°å¯»ä¼˜è„šæœ¬è¿›è¡Œå®éªŒ")
        return
    
    # æŒ‰é¢„æµ‹é•¿åº¦åˆ†ç»„åˆ†æ
    results_by_pred_len = find_best_params_by_pred_len(results, args.pred_lens)
    
    # æ‰“å°æ±‡æ€»è¡¨æ ¼
    print_summary_table(results_by_pred_len, args.pred_lens)
    
    # æ‰“å°æ¯ä¸ªé¢„æµ‹é•¿åº¦çš„è¯¦ç»†ç»“æœï¼ˆä¼ å…¥æ‰€æœ‰ç»“æœç”¨äºç§å­ç»Ÿè®¡ï¼‰
    # print_results_by_pred_len(results_by_pred_len, args.pred_lens, all_results=results)
    
    # print("\n" + "="*80)
    # print("åˆ†æå®Œæˆï¼")
    # print("="*80)

if __name__ == "__main__":
    main()

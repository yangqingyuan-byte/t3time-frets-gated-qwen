#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""å¿«é€Ÿæµ‹è¯• V30 æ¨¡å‹çš„å‰å‘ä¼ æ’­å’Œ Frequency Dropout"""
import torch
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from models.T3Time_Learnable_Wavelet_Packet_Gated_Pro_Qwen import TriModalLearnableWaveletPacketGatedProQwen

def test_v30():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"Using device: {device}")
    
    # åˆ›å»ºæ¨¡å‹å®ä¾‹ï¼ˆV30 é…ç½®ï¼‰
    model = TriModalLearnableWaveletPacketGatedProQwen(
        device=device,
        channel=128,
        num_nodes=7,
        seq_len=96,
        pred_len=96,
        dropout_n=0.5,
        wp_level=2
    ).to(device)
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 2
    x = torch.randn(batch_size, 96, 7).to(device)  # [B, L, N]
    x_mark = torch.randn(batch_size, 96, 4).to(device)  # [B, L, 4]
    emb = torch.randn(batch_size, 1024, 7, 1).to(device)  # [B, d_llm, N, 1]
    
    print(f"Input shapes:")
    print(f"  x: {x.shape}")
    print(f"  x_mark: {x_mark.shape}")
    print(f"  emb: {emb.shape}")
    
    # æµ‹è¯•è®­ç»ƒæ¨¡å¼ï¼ˆFrequency Dropout åº”è¯¥ç”Ÿæ•ˆï¼‰
    model.train()
    with torch.no_grad():
        output_train = model(x, x_mark, emb)
    
    print(f"\nTraining mode output shape: {output_train.shape}")
    
    # æµ‹è¯•è¯„ä¼°æ¨¡å¼ï¼ˆFrequency Dropout åº”è¯¥å…³é—­ï¼‰
    model.eval()
    with torch.no_grad():
        output_eval = model(x, x_mark, emb)
    
    print(f"Eval mode output shape: {output_eval.shape}")
    
    # éªŒè¯è¾“å‡ºå½¢çŠ¶
    assert output_train.shape == (batch_size, 96, 7), f"Training output shape mismatch! Got {output_train.shape}, expected ({batch_size}, 96, 7)"
    assert output_eval.shape == (batch_size, 96, 7), f"Eval output shape mismatch! Got {output_eval.shape}, expected ({batch_size}, 96, 7)"
    
    # æ£€æŸ¥æ˜¯å¦æœ‰ NaN æˆ– Inf
    assert not torch.isnan(output_train).any(), "Training output contains NaN!"
    assert not torch.isinf(output_train).any(), "Training output contains Inf!"
    assert not torch.isnan(output_eval).any(), "Eval output contains NaN!"
    assert not torch.isinf(output_eval).any(), "Eval output contains Inf!"
    
    print("\nâœ… V30 æ¨¡å‹æµ‹è¯•é€šè¿‡ï¼")
    print("âœ… æ¨¡å‹å·²æˆåŠŸæ¢å¤ V25 ç»“æ„ï¼ˆPrior Init, Pre-Normï¼‰")
    print("âœ… Frequency Dropout å·²å®ç°ï¼ˆè®­ç»ƒ/è¯„ä¼°æ¨¡å¼åˆ‡æ¢æ­£å¸¸ï¼‰")
    
    # æ£€æŸ¥å…³é”®ç»„ä»¶
    print("\nå…³é”®ç»„ä»¶æ£€æŸ¥:")
    print(f"  âœ… length_to_feature: {type(model.length_to_feature).__name__} (åº”è¯¥æ˜¯ Linear)")
    print(f"  âœ… ts_encoder FFN: {model.ts_encoder[0].linear1.out_features} (åº”è¯¥æ˜¯ {2048} æˆ– {4*128})")
    print(f"  âœ… wp_encoder FFN: {model.wp_encoder.linear1.out_features} (åº”è¯¥æ˜¯ {2048} æˆ– {4*128})")
    
    # æ£€æŸ¥ Prior Init
    band_weights = model.band_weights.data
    print(f"  âœ… band_weights[0, 0]: {band_weights[0, 0].item():.2f} (åº”è¯¥æ˜¯ 1.0)")
    print(f"  âœ… band_weights[1, 0]: {band_weights[1, 0].item():.2f} (åº”è¯¥æ˜¯ -1.0)")
    
    # æ£€æŸ¥ Pre-Normï¼ˆé€šè¿‡æŸ¥çœ‹ wp_processing ä¸­çš„ä»£ç ç»“æ„ï¼‰
    print(f"  âœ… cf_norm å­˜åœ¨: {hasattr(model, 'cf_norm')}")
    print(f"  âœ… æ—  trend_projector: {'trend_projector' not in dir(model)}")
    
    print("\nğŸ¯ V30 å‡†å¤‡å°±ç»ªï¼å¯ä»¥å¼€å§‹è®­ç»ƒäº†ã€‚")

if __name__ == "__main__":
    test_v30()
